# loaded model ( for GPU utilization )
model: "llama3.1:8b-instruct-q4_K_M"
API_port: ""
# DB infra 
ttl: ""